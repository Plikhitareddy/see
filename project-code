import dlib
import cv2
import face_recognition
import numpy as np
import pyttsx3
import os
import pyaudio
import speech_recognition as sr
import os
import pywhatkit
import datetime
import wikipedia
import pyjokes
import os
import google.generativeai as genai

output_directory = r"C:\Users\palik\OneDrive\Desktop\database"
if not os.path.exists(output_directory):
    os.makedirs(output_directory)

video_capture = cv2.VideoCapture(0)

listener = sr.Recognizer()

#transformers
def take_command():
    try:
        with sr.Microphone() as source:
            print('listening...')
            listener.adjust_for_ambient_noise(source, duration=0.2)
            voice = listener.listen(source)
            command = listener.recognize_google(voice)
            command = command.lower()
            print(command)
    except sr.UnknownValueError():
        take_command()

    return command


def load_known_faces(known_faces_folder):
    known_face_encodings = []
    known_face_names = []

    for filename in os.listdir(known_faces_folder):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            # Load the image file
            image_path = os.path.join(known_faces_folder, filename)
            image = face_recognition.load_image_file(image_path)

            # Find face encodings in the image
            face_encodings = face_recognition.face_encodings(image)

            if len(face_encodings) > 0:
                # Use the face encoding for the first face in the image
                face_encoding = face_encodings[0]

                # Extract the name from the filename (assuming the filename is in the format "Name.jpg")
                name = os.path.splitext(filename)[0]

                # Append the face encoding and name to the lists
                known_face_encodings.append(face_encoding)
                known_face_names.append(name)

    return known_face_encodings, known_face_names


known_face_encodings, known_face_names = load_known_faces(output_directory)


def get_face_encodings(photo_path):
    image = face_recognition.load_image_file(photo_path)

    # Find all face locations and face encodings in the image
    face_locate = face_recognition.face_locations(image)
    face_encode = face_recognition.face_encodings(image, face_locate)

    return face_encode


listener = sr.Recognizer()
engine = pyttsx3.init()
voices = engine.getProperty('voices')
engine.setProperty('voice', voices[1].id)


def talk(text):
    engine.say(text)
    engine.runAndWait()

#take command
def take_command():
    try:
        with sr.Microphone() as source:
            print('listening...')
            listener.adjust_for_ambient_noise(source, duration=0.2)
            voice = listener.listen(source)
            command = listener.recognize_google(voice)
            command = command.lower()
            print(command)
    except sr.UnknownValueError():
        take_command()

    return command


os.environ['GOOGLE_API_KEY'] = "AIzaSyAgRO6QipTninhxpZxp6NwsChDRttPNx6o"
genai.configure(api_key=os.environ['GOOGLE_API_KEY'])
model = genai.GenerativeModel('gemini-pro')

face_locations = []
face_encoding = []
s = True
while True:
    img,frame=video_capture.read()
    small_frame=cv2.resize(frame,(0,0),fx=0.25,fy=0.25)
    rgb_small_frame=cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
    if s:
        face_locations=face_recognition.face_locations(rgb_small_frame)
        face_encodings=face_recognition.face_encodings(rgb_small_frame,face_locations)
        face_names=[]
        for face_encoding in face_encodings:
            matches=face_recognition.compare_faces(known_face_encodings,face_encoding)
            name=""
            face_distance=face_recognition.face_distance(known_face_encodings,face_encoding)
            best_match_index=np.argmin(face_distance)
            if matches[best_match_index]:
                name=known_face_names[best_match_index]
                speaker = pyttsx3.init()
                voicerate=190
                speaker.setProperty('rate',voicerate)
                print("hi how are you,welcome to class")
                speaker.say(f"hi how are you , welcome to class")
                speaker.runAndWait()
                name+=".txt"
                talk("Do you want to write or Do you want to speak")
                enter=input("write or speak:")

                if enter=="speak":
                    def run():
                        with open(name, 'a') as file:
                            command =take_command()
                            file.write("\n" + command)
                            file.close()
                            if 'play' in command:
                                song = command.replace('play', '')
                                talk('playing ' + song)
                                pywhatkit.playonyt(song)
                                run()
                            elif 'time' in command:
                                time = datetime.datetime.now().strftime('%I:%M %p')
                                talk('Current time is ' + time)
                                run()
                            elif 'who the heck is' in command:
                                person = command.replace('who the heck is', '')
                                info = wikipedia.summary(person, 1)
                                print(info)
                                talk(info)
                                run()
                            elif 'okay' in command:
                                run()
                            elif 'stop' in command:
                                return False
                                exit()
                            elif 'date' in command:
                                talk('sorry, I have a headache')
                                run()
                            elif 'are you single' in command:
                                talk('I am in a relationship with wifi')
                                run()
                            elif 'what is your name' in command:
                                talk("hi i am teja and i am your personal assistant")
                                run()
                            elif 'joke' in command:
                                talk(pyjokes.get_joke())
                                run()
                            elif 'are you fine' in command:
                                talk("yes my dear,I am fine")
                            elif 'I miss you so much' in command:
                                talk('my  dear i am always with you ')
                            else:
                                response = model.generate_content(command)
                                print(response.text)
                                talk(response.text)
                                run()
                else:
                    def run():
                        with open(name, 'a') as file:
                            command = input("write now: ")
                            file.write("\n" + command)
                            file.close()
                            if 'play' in command:
                                song = command.replace('play', '')
                                talk('playing ' + song)
                                pywhatkit.playonyt(song)
                                run()
                            elif 'time' in command:
                                time = datetime.datetime.now().strftime('%I:%M %p')
                                talk('Current time is ' + time)
                                run()
                            elif 'who the heck is' in command:
                                person = command.replace('who the heck is', '')
                                info = wikipedia.summary(person, 1)
                                print(info)
                                talk(info)
                                run()
                            elif 'okay' in command:
                                run()
                            elif 'stop' in command:
                                return False
                                exit()
                            elif 'date' in command:
                                talk('sorry, I have a headache')
                                run()
                            elif 'are you single' in command:
                                talk('I am in a relationship with wifi')
                                run()
                            elif 'what is your name' in command:
                                talk("hi i am teja and i am your personal assistant")
                                run()
                            elif 'joke' in command:
                                talk(pyjokes.get_joke())
                                run()
                            elif 'are you fine' in command:
                                talk("yes my dear,I am fine")
                            elif 'I miss you so much' in command:
                                talk('my  dear i am always with you ')
                            else:
                                response = model.generate_content(command)
                                print(response.text)
                                talk(response.text)
                                run()



                if True:
                        run()
                else:
                        file.close()
            else:
                voicerate = 190
                speaker = pyttsx3.init()
                speaker.setProperty('rate', voicerate)
                speaker.say(f"what is your name")
                speaker.runAndWait()
                command = input("enter your name here: ")
                face_locations = face_recognition.face_locations(rgb_small_frame)
                face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
                image_path = os.path.join(output_directory, f"{command}.jpg")
                cv2.imwrite(image_path, frame)
                image = os.path.join(output_directory, f"{command}.jpg")
                exit()

    cv2.imshow("attendence system", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
video_capture.release()
cv2.destroyAllWindows()
